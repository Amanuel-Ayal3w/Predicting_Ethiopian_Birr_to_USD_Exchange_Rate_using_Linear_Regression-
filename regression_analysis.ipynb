{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell 2: Load and Inspect the Dataset\n",
    "file_path = \"ETB.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove columns with 'Unnamed' in their name\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocessing\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data[\"Days\"] = (data[\"Date\"] - data[\"Date\"].min()).dt.days\n",
    "data[\"Weight\"] = np.where(data[\"Date\"] >= pd.to_datetime(\"2020-01-01\"), 8, 1)  # Increase weight to 5 for data after 2020\n",
    "data_cleaned = data.dropna()\n",
    "features = data_cleaned[[\"Days\", \"Open\", \"Low\"]]\n",
    "target = data_cleaned[\"High\"]\n",
    "weights = data_cleaned[\"Weight\"]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Hyperparameter Tuning using Gradient Descent\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize alpha\n",
    "alpha = 1.0\n",
    "\n",
    "# Define learning rate and number of iterations\n",
    "learning_rate = 0.01\n",
    "num_iterations = 100\n",
    "\n",
    "# Function to compute the gradient of the loss with respect to alpha\n",
    "def compute_gradient(X, y, model, alpha):\n",
    "    model.set_params(alpha=alpha)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    gradient = -2 * np.sum((y - y_pred) * y_pred) / len(y)\n",
    "    return gradient\n",
    "\n",
    "# Gradient descent loop\n",
    "for i in range(num_iterations):\n",
    "    model = Ridge(alpha=alpha)\n",
    "    gradient = compute_gradient(X_train, y_train, model, alpha)\n",
    "    alpha -= learning_rate * gradient\n",
    "    print(f\"Iteration {i+1}: alpha = {alpha}\")\n",
    "\n",
    "# Train the final model with the optimized alpha\n",
    "final_model = Ridge(alpha=alpha)\n",
    "final_model.fit(X_train, y_train, sample_weight=weights.loc[X_train.index])\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Optimized alpha: {alpha}\")\n",
    "print(f\"Test Mean Squared Error: {mse}\")\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "print(f\"Test R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train the Model\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train, sample_weight=weights.loc[X_train.index])\n",
    "coefficients = pd.DataFrame({\"Feature\": features.columns, \"Coefficient\": model.coef_})\n",
    "print(coefficients)\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate the Model\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Visualization\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.7, color=\"blue\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted High Values\")\n",
    "plt.show()\n",
    "\n",
    "days_range = np.linspace(features[\"Days\"].min(), features[\"Days\"].max(), 100).reshape(-1, 1)\n",
    "mean_values = np.mean(features[[\"Open\", \"Low\"]], axis=0).values.reshape(1, -1)\n",
    "mean_values_repeated = np.repeat(mean_values, days_range.shape[0], axis=0)\n",
    "high_pred_line = model.predict(np.hstack([days_range, mean_values_repeated]))\n",
    "\n",
    "# Plot the regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features[\"Days\"], target, alpha=0.5, label=\"Actual Data\")\n",
    "plt.plot(days_range, high_pred_line, color=\"red\", label=\"Regression Line\")\n",
    "plt.xlabel(\"Days Since Start\")\n",
    "plt.ylabel(\"High Price\")\n",
    "plt.title(\"Regression Line with Multiple Features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prediction Interface\n",
    "def predict_high(input_date):\n",
    "    input_date = pd.to_datetime(input_date)\n",
    "    days_since_start = (input_date - data_cleaned[\"Date\"].min()).days\n",
    "    closest_row = data_cleaned.iloc[(data_cleaned[\"Days\"] - days_since_start).abs().argmin()]\n",
    "    open_val = closest_row[\"Open\"]\n",
    "    low_val = closest_row[\"Low\"]\n",
    "    prediction = model.predict([[days_since_start, open_val, low_val]])[0]\n",
    "    return prediction\n",
    "\n",
    "input_date = input(\"Enter Date (YYYY-MM-DD): \")\n",
    "predicted_high = predict_high(input_date)\n",
    "print(f\"Predicted High for {input_date}: {predicted_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
